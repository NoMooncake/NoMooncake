<!-- HEADER -->
<h1 align="center">Davie Wu</h1>
<h3 align="center">
Research-Oriented Computer Science · Human-Centered Data Systems
</h3>

<p align="center">
Exploring how data, machine learning, and design frameworks
can support human decision-making under uncertainty.
</p>

---

## Research Statement

I am interested in **how people make decisions in complex, information-dense environments**, and how **data-driven systems can be designed to reduce cognitive overload rather than amplify it**.

My work explores:
- how raw data can be structured into **decision frameworks**
- how machine learning models can remain **interpretable and trustworthy**
- how visualization and interaction design influence **sensemaking**

Rather than optimizing models in isolation, I focus on **human-centered data systems** that support clarity, comparison, and reflection.

---

## Research Interests

- Decision-making under uncertainty  
- Information overload & cognitive framing  
- Explainable and interpretable machine learning  
- Data-driven sensemaking tools  
- Human–AI interaction  
- Generative AI for analysis & storytelling  

---

## Education

**M.S. in Computer Science**  
*Northeastern University, Miami*

Background in data science, machine learning, and system design, with strong interests in research-oriented and design-integrated applications of AI.

---

## Selected Research Systems & Studies

### Mira — AI-Powered Reflective Companion *(Flagship System)*  
**Repository:** https://github.com/NoMooncake/mira-astrology-companion  

A large-scale, cloud-native AI system exploring how **LLM-based agents can support emotional reflection and decision-making**, rather than task completion.

**Research focus:**
- Human-centered conversational AI
- Explainable emotional risk flagging
- Reflection over optimization
- System-level tradeoffs (cost, latency, interpretability)

**Highlights:**
- Serverless architecture (AWS Lambda, API Gateway, DynamoDB, Bedrock)
- Rule-based + LLM hybrid reasoning
- Cost-sensitive design decisions
- Synthetic-data-first research ethics

> Mira functions as a **living research system**, integrating architecture, ML reasoning, and human-centered design.

---
### Behavior-State Modeling — User State Recognition Framework

**Repository:** https://github.com/NoMooncake/behavior-state-modeling

A research-oriented framework for modeling and inferring **latent user behavioral states** from interaction patterns, designed to support downstream decision-support and adaptive systems.

The project focuses on translating low-level behavioral signals into **interpretable, high-level user states** (e.g., focused, disengaged, erratic), emphasizing structure and explainability over black-box prediction.

**Research focus:**
- Behavior-to-state abstraction
- Interpretable user state modeling
- Temporal patterns and session-level signals
- Decision-support foundations for adaptive systems

**Key characteristics:**
- Rule-based and feature-driven state inference
- Session-level aggregation of behavioral signals
- Explicit state definitions with human-readable criteria
- Designed as a modeling layer, not a recommendation engine

> This project serves as a **foundational modeling layer** for understanding user behavior before intervention, personalization, or automation.

---

### Social Media Attention & Trend Sensemaking  
Demo: https://nomooncake.github.io/YueWu3160  

A data-driven study examining **how attention and trends form across TikTok and YouTube**, and how social platforms structure the information environments in which users make decisions.

---

### Robustness under Bad Data  
**Repository:** https://github.com/NoMooncake/wine-bad-data-robustness  

An empirical study on **how machine learning models degrade under label noise, missing values, and corrupted data**, focusing on robustness rather than peak accuracy.

**Research focus:**
- Failure modes of ML models
- Robust evaluation under non-ideal data
- Comparative behavior across model families

---

### Mini-Vibes — Explainable Risk Flagging Prototype  
**Repository:** https://github.com/NoMooncake/mini-vibes  

A lightweight, rule-based prototype for **emotion-aware risk flagging** in short journal entries, designed for interpretability over prediction.

**Research focus:**
- Explainability-first AI
- Conservative, non-diagnostic design
- Human-in-the-loop decision support

---

### Mini-Autograd — Learning from First Principles  
**Repository:** https://github.com/NoMooncake/mini-autograd  

A minimal autograd engine built from scratch to study **backpropagation, computational graphs, and learning dynamics**.

**Research focus:**
- Understanding learning mechanisms
- Transparency in optimization
- Educational and interpretive ML tooling

---

### Meal Planner — Constraint-Based Daily Decisions  
**Repository:** https://github.com/NoMooncake/meal-planner  

A Java-based system modeling **everyday decision-making under constraints**, combining pantry state, preferences, and recipe logic.

**Research focus:**
- Decision modeling in daily life
- Constraint satisfaction vs recommendation
- Modular system design


---

## Methods & Tools

### Data & ML
- Statistical modeling
- Interpretable machine learning
- Feature analysis & evaluation
- ETL pipelines & exploratory analysis

### Systems & Design
- Modular system architecture
- MVC & design patterns
- Decision framework design
- Visualization & narrative structure

### Technical Stack
Python · Java · SQL · Pandas · NumPy · scikit-learn · PyTorch  
Tableau · Docker · AWS · Git · Jupyter · Maven

---

## Current Research Directions

- Designing **decision-support systems** rather than prediction-only models  
- Exploring **Generative AI** as a co-analyst and explanatory agent  
- Studying how different data representations influence user judgment  
- Bridging **machine learning + interaction design**

---

## Open Questions

- How much model accuracy should be sacrificed for interpretability?
- When does more information reduce decision quality?
- Can AI systems explain *why not* instead of only *why*?
- How can data systems support reflection instead of speed?

---

## Contact

- Portfolio: https://NoMooncake.github.io  
- LinkedIn: https://www.linkedin.com/in/yue-wu-030816d  
- Email: wu.y26@northeastern.edu

---

*This GitHub serves as a living research notebook rather than a showcase of finished products.*
